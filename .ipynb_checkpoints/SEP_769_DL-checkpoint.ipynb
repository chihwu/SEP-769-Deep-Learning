{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/chihwu/SEP-769-Deep-Learning/blob/master/SEP_769_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Js7b1QAXmGAb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0OIOjdRIWPw"
   },
   "source": [
    "# Load Data, Format Labels, Split Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0y7yc68uQbJN",
    "outputId": "28c109e7-bed9-43fc-bc31-21677e01ad38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vid_4_1000.jpg</td>\n",
       "      <td>281.259045</td>\n",
       "      <td>187.035071</td>\n",
       "      <td>327.727931</td>\n",
       "      <td>223.225547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vid_4_10000.jpg</td>\n",
       "      <td>15.163531</td>\n",
       "      <td>187.035071</td>\n",
       "      <td>120.329957</td>\n",
       "      <td>236.430180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vid_4_10040.jpg</td>\n",
       "      <td>239.192475</td>\n",
       "      <td>176.764800</td>\n",
       "      <td>361.968162</td>\n",
       "      <td>236.430180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vid_4_10020.jpg</td>\n",
       "      <td>496.483358</td>\n",
       "      <td>172.363256</td>\n",
       "      <td>630.020261</td>\n",
       "      <td>231.539575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vid_4_10060.jpg</td>\n",
       "      <td>16.630970</td>\n",
       "      <td>186.546010</td>\n",
       "      <td>132.558611</td>\n",
       "      <td>238.386422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image        xmin        ymin        xmax        ymax\n",
       "0   vid_4_1000.jpg  281.259045  187.035071  327.727931  223.225547\n",
       "1  vid_4_10000.jpg   15.163531  187.035071  120.329957  236.430180\n",
       "2  vid_4_10040.jpg  239.192475  176.764800  361.968162  236.430180\n",
       "3  vid_4_10020.jpg  496.483358  172.363256  630.020261  231.539575\n",
       "4  vid_4_10060.jpg   16.630970  186.546010  132.558611  238.386422"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import csv with bounding box labels\n",
    "df = pd.read_csv('data/train_solution_bounding_boxes (1).csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dXFby_oueAf",
    "outputId": "44939a78-30a3-4c03-a7b6-00dd4b4d4fb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vid_4_1000.jpg', 'vid_4_10000.jpg', 'vid_4_10020.jpg', 'vid_4_10040.jpg', 'vid_4_10060.jpg']\n",
      "Number of validation images: 200\n"
     ]
    }
   ],
   "source": [
    "#import image names as a list\n",
    "images = os.listdir('data/training_images/')\n",
    "print(images[0:5])\n",
    "\n",
    "#create validation set of images\n",
    "random.seed(4)\n",
    "n = round(0.2 * len(images))\n",
    "val = random.sample(images, n)\n",
    "print('Number of validation images:', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "yZrIWl6L_Mj4",
    "outputId": "7710ad2e-2830-4c7a-fb8d-88eacca7d962"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vid_4_1000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450434</td>\n",
       "      <td>0.539817</td>\n",
       "      <td>0.068741</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vid_4_10000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100217</td>\n",
       "      <td>0.557191</td>\n",
       "      <td>0.155572</td>\n",
       "      <td>0.129987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vid_4_10040.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444645</td>\n",
       "      <td>0.543678</td>\n",
       "      <td>0.181621</td>\n",
       "      <td>0.157014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vid_4_10020.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833213</td>\n",
       "      <td>0.531451</td>\n",
       "      <td>0.197540</td>\n",
       "      <td>0.155727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vid_4_10060.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.110347</td>\n",
       "      <td>0.559122</td>\n",
       "      <td>0.171491</td>\n",
       "      <td>0.136422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image  class  x_center  y_center     width    height\n",
       "0   vid_4_1000.jpg      0  0.450434  0.539817  0.068741  0.095238\n",
       "1  vid_4_10000.jpg      0  0.100217  0.557191  0.155572  0.129987\n",
       "2  vid_4_10040.jpg      0  0.444645  0.543678  0.181621  0.157014\n",
       "3  vid_4_10020.jpg      0  0.833213  0.531451  0.197540  0.155727\n",
       "4  vid_4_10060.jpg      0  0.110347  0.559122  0.171491  0.136422"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert bounding box to yolo format (x_center, y_center, width, height and normalize 0 - 1)\n",
    "frame = cv2.imread('data/training_images/' + images[0])\n",
    "h, w, colour = frame.shape\n",
    "\n",
    "df['class'] = 0\n",
    "df['x_center'] = (df['xmin'] +  (df['xmax'] - df['xmin']) / 2 ) / w\n",
    "df['y_center'] = (df['ymin'] +  (df['ymax'] - df['ymin']) / 2 ) / h\n",
    "df['width'] = (df['xmax'] - df['xmin']) / w\n",
    "df['height'] = (df['ymax'] - df['ymin']) / h\n",
    "\n",
    "df = df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_PnMdWnLjBkO"
   },
   "outputs": [],
   "source": [
    "#Save images and labels - one text file per image\n",
    "for im in images:\n",
    "  frame = cv2.imread('data/training_images/{}'.format(im))\n",
    "  df_image = df[df['image'] == im]\n",
    "  df_image = df_image.drop(['image'], axis = 1)\n",
    "  df_image.head()\n",
    "  lbl = im[0:-3] + 'txt'\n",
    "  #print(lbl)\n",
    "  \n",
    "  if im in val:    \n",
    "    cv2.imwrite('data/yolo/valid/images/{}'.format(im), frame)\n",
    "    df_image.to_csv('data/yolo/valid/labels/{}'.format(lbl), \n",
    "                    header=None, index=None, sep=' ', mode='a')\n",
    "  else:\n",
    "    cv2.imwrite('data/yolo/train/images/{}'.format(im), frame)\n",
    "    df_image.to_csv('data/yolo/train/labels/{}'.format(lbl), \n",
    "                    header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "SQ9xrypnQjK6"
   },
   "outputs": [],
   "source": [
    "#Augment Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347.2937771499999 209.77638355 121.30824890000002 44.50450449999997\n"
     ]
    }
   ],
   "source": [
    "x_c = 0.5137481910502958 * w\n",
    "y_c = 0.5520431146052631 * h\n",
    "x_w = 0.17945007233727814 * w\n",
    "y_w = 0.11711711710526307 * h\n",
    "\n",
    "print(x_c, y_c, x_w, y_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328.7062228500001"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_c = -1 * x_c + w\n",
    "new_x_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48625180894970427"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_c / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_img(img_name):\n",
    "    # flip the image and save the new image\n",
    "    img = cv2.imread('yolo_test_images/{}'.format(img_name))\n",
    "    img_flip_lr = cv2.flip(img, 1)  # we only flip horizontally in our case\n",
    "    cv2.imwrite('yolo_test_images/{}_dg.jpg'.format(img_name[0:-4]), img_flip_lr)\n",
    "    \n",
    "    # flip the bounding boxes\n",
    "    img_height, img_width, color = img.shape\n",
    "    \n",
    "    r_f = open('yolo_test_images/{}.txt'.format(img_name[0:-4]), 'r')\n",
    "    lines = r_f.readlines()\n",
    "    \n",
    "    w_f = open('yolo_test_images/{}_dg.txt'.format(img_name[0:-4]), \"w\")\n",
    "    new_lines = []\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i].split()\n",
    "        normalized_bbox_center_x = float(line[1])\n",
    "        normalized_bbox_center_y = float(line[2])\n",
    "        normalized_bbox_width = float(line[3])\n",
    "        normalized_bbox_height = float(line[4])\n",
    "    \n",
    "        bbox_center_x = normalized_bbox_center_x * img_width\n",
    "        new_bbox_center_x = -1 * bbox_center_x + img_width\n",
    "        normalized_bbox_center_x = new_bbox_center_x / img_width\n",
    "        \n",
    "        new_line = \"{} {} {} {} {}\\n\".format(line[0], normalized_bbox_center_x, normalized_bbox_center_y, normalized_bbox_width, normalized_bbox_height);\n",
    "        new_lines.append(new_line)\n",
    "    \n",
    "    w_f.writelines(new_lines)\n",
    "    w_f.close()\n",
    "    r_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_img(img_name):\n",
    "    # flip the image and save the new image\n",
    "    img = cv2.imread('yolo_test_images/{}'.format(img_name))\n",
    "    # flip the bounding boxes\n",
    "    img_height, img_width, color = img.shape\n",
    "    \n",
    "    scale_percent = 1.2\n",
    "    img_width *= scale_percent\n",
    "    img_height *= scale_percent\n",
    "    \n",
    "    img_resized = cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    cv2.imshow(\"Original Img\", img)\n",
    "    cv2.imshow(\"Resized Img\", img_resized)\n",
    "    \n",
    "#     cv2.imwrite('yolo_test_images/{}_dg.jpg'.format(img_name[0:-4]), img_resized)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     r_f = open('yolo_test_images/{}.txt'.format(img_name[0:-4]), 'r')\n",
    "#     lines = r_f.readlines()\n",
    "    \n",
    "#     w_f = open('yolo_test_images/{}_dg.txt'.format(img_name[0:-4]), \"w\")\n",
    "#     new_lines = []\n",
    "    \n",
    "#     for i in range(len(lines)):\n",
    "#         line = lines[i].split()\n",
    "#         normalized_bbox_center_x = float(line[1])\n",
    "#         normalized_bbox_center_y = float(line[2])\n",
    "#         normalized_bbox_width = float(line[3])\n",
    "#         normalized_bbox_height = float(line[4])\n",
    "    \n",
    "#         bbox_center_x = normalized_bbox_center_x * img_width\n",
    "#         new_bbox_center_x = -1 * bbox_center_x + img_width\n",
    "#         normalized_bbox_center_x = new_bbox_center_x / img_width\n",
    "        \n",
    "#         new_line = \"{} {} {} {} {}\\n\".format(line[0], normalized_bbox_center_x, normalized_bbox_center_y, normalized_bbox_width, normalized_bbox_height);\n",
    "#         new_lines.append(new_line)\n",
    "    \n",
    "#     w_f.writelines(new_lines)\n",
    "#     w_f.close()\n",
    "#     r_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_img('vid_4_700.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('yolo_test_images/vid_4_700.jpg')\n",
    "# flip the bounding boxes\n",
    "img_height, img_width, color = img.shape\n",
    "\n",
    "scale_percent = 1.6\n",
    "scaled_img_width = img_width * scale_percent\n",
    "scaled_img_height = img_height * scale_percent\n",
    "\n",
    "img_resized = cv2.resize(img, (int(scaled_img_width), int(scaled_img_height)), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "min_width = round(scaled_img_width/2 - img_width/2)\n",
    "max_width = round(min_width + img_width)\n",
    "min_height = round(scaled_img_height/2 - img_height/2)\n",
    "max_height = round(min_height + img_height)\n",
    "\n",
    "# img_resized = img_resized[min_height:max_height, min_width:max_width]\n",
    "\n",
    "cv2.imwrite('yolo_test_images/vid_4_700_dg.jpg', img_resized)\n",
    "\n",
    "\n",
    "\n",
    "r_f = open('yolo_test_images/vid_4_700.txt', 'r')\n",
    "lines = r_f.readlines()\n",
    "\n",
    "w_f = open('yolo_test_images/vid_4_700_dg.txt', \"w\")\n",
    "new_lines = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i].split()\n",
    "    normalized_bbox_center_x = float(line[1])\n",
    "    normalized_bbox_center_y = float(line[2])\n",
    "    normalized_bbox_width = float(line[3])\n",
    "    normalized_bbox_height = float(line[4])\n",
    "\n",
    "    bbox_center_x = normalized_bbox_center_x * img_width\n",
    "    bbox_center_y = normalized_bbox_center_y * img_height\n",
    "    bbox_width = normalized_bbox_width * img_width\n",
    "    bbox_height = normalized_bbox_height * img_height\n",
    "    \n",
    "    normalized_bbox_center_x = (bbox_center_x + scaled_img_width * 0.6 ) / scaled_img_width\n",
    "    normalized_bbox_center_y = (bbox_center_y - scaled_img_height * 0.6) / scaled_img_height\n",
    "    normalized_bbox_width = bbox_width * scale_percent / img_width\n",
    "    normalized_bbox_height = bbox_height * scale_percent / img_height\n",
    "\n",
    "    new_line = \"{} {} {} {} {}\\n\".format(line[0], normalized_bbox_center_x, normalized_bbox_center_y, normalized_bbox_width, normalized_bbox_height)\n",
    "    new_lines.append(new_line)\n",
    "\n",
    "w_f.writelines(new_lines)\n",
    "w_f.close()\n",
    "r_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 676, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(570, 1014, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "R6rSqIaMQ17E"
   },
   "outputs": [],
   "source": [
    "#Train simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ksz2YRbmQ4VV"
   },
   "outputs": [],
   "source": [
    "#Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w6wEgFTQQ7EM"
   },
   "outputs": [],
   "source": [
    "#Test with Yolo"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3/kjoV2rE2V8j9FAiFUwh",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SEP-769-DL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
